{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/eBRPvWB.png)\n",
    "\n",
    "# Practical PyTorch: Translation with a Sequence to Sequence Network and Attention\n",
    "\n",
    "In this project we will be teaching a neural network to translate from French to English.\n",
    "\n",
    "```\n",
    "[KEY: > input, = target, < output]\n",
    "\n",
    "> il est en train de peindre un tableau .\n",
    "= he is painting a picture .\n",
    "< he is painting a picture .\n",
    "\n",
    "> pourquoi ne pas essayer ce vin delicieux ?\n",
    "= why not try that delicious wine ?\n",
    "< why not try that delicious wine ?\n",
    "\n",
    "> elle n est pas poete mais romanciere .\n",
    "= she is not a poet but a novelist .\n",
    "< she not not a poet but a novelist .\n",
    "\n",
    "> vous etes trop maigre .\n",
    "= you re too skinny .\n",
    "< you re all alone .\n",
    "```\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the [sequence to sequence network](http://arxiv.org/abs/1409.3215), in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a single vector, and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "To improve upon this model we'll use an [attention mechanism](https://arxiv.org/abs/1409.0473), which lets the decoder learn to focus over a specific range of the input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Learning\n",
    "\n",
    "A [Sequence to Sequence network](http://arxiv.org/abs/1409.3215), or seq2seq network, or [Encoder Decoder network](https://arxiv.org/pdf/1406.1078v3.pdf), is a model consisting of two separate RNNs called the **encoder** and **decoder**. The encoder reads an input sequence one item at a time, and outputs a vector at each step. The final output of the encoder is kept as the **context** vector. The decoder uses this context vector to produce a sequence of outputs one step at a time.\n",
    "\n",
    "![](https://i.imgur.com/tVtHhNp.png)\n",
    "\n",
    "When using a single RNN, there is a one-to-one relationship between inputs and outputs. We would quickly run into problems with different sequence orders and lengths that are common during translation. Consider the simple sentence \"Je ne suis pas le chat noir\" &rarr; \"I am not the black cat\". Many of the words have a pretty direct translation, like \"chat\" &rarr; \"cat\". However the differing grammars cause words to be in different orders, e.g. \"chat noir\" and \"black cat\". There is also the \"ne ... pas\" &rarr; \"not\" construction that makes the two sentences have different lengths.\n",
    "\n",
    "With the seq2seq model, by encoding many inputs into one vector, and decoding from one vector into many outputs, we are freed from the constraints of sequence order and length. The encoded sequence is represented by a single vector, a single point in some N dimensional space of sequences. In an ideal case, this point can be considered the \"meaning\" of the sequence.\n",
    "\n",
    "This idea can be extended beyond sequences. Image captioning tasks take an [image as input, and output a description](https://arxiv.org/abs/1411.4555) of the image (img2seq). Some image generation tasks take a [description as input and output a generated image](https://arxiv.org/abs/1511.02793) (seq2img). These models can be referred to more generally as \"encoder decoder\" networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Attention Mechanism\n",
    "\n",
    "The fixed-length vector carries the burden of encoding the the entire \"meaning\" of the input sequence, no matter how long that may be. With all the variance in language, this is a very hard problem. Imagine two nearly identical sentences, twenty words long, with only one word different. Both the encoders and decoders must be nuanced enough to represent that change as a very slightly different point in space.\n",
    "\n",
    "The **attention mechanism** [introduced by Bahdanau et al.](https://arxiv.org/abs/1409.0473) addresses this by giving the decoder a way to \"pay attention\" to parts of the input, rather than relying on a single vector. For every step the decoder can select a different part of the input sentence to consider.\n",
    "\n",
    "![](https://i.imgur.com/5y6SCvU.png)\n",
    "\n",
    "Attention is calculated using the current hidden state and each encoder output, resulting in a vector the same size as the input sequence, called the *attention weights*. These weights are multiplied by the encoder outputs to create a weighted sum of encoder outputs, which is called the *context* vector. The context vector and hidden state are used to predict the next output element.\n",
    "\n",
    "![](https://i.imgur.com/K1qMPxs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "You will need [PyTorch](http://pytorch.org/) to build and train the models, and [matplotlib](https://matplotlib.org/) for plotting training and visualizing attention outputs later. The rest are builtin Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will also define a constant to decide whether to use the GPU (with CUDA specifically) or the CPU. **If you don't have a GPU, set this to `False`**. Later when we create tensors, this variable will be used to decide whether we keep them on CPU or move them to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data files\n",
    "\n",
    "The data for this project is a set of many thousands of English to French translation pairs.\n",
    "\n",
    "[This question on Open Data Stack Exchange](http://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages) pointed me to the open translation site http://tatoeba.org/ which has downloads available at http://tatoeba.org/eng/downloads - and better yet, someone did the extra work of splitting language pairs into individual text files here: http://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so download `fra-eng.zip`, extract the text file in there, and rename it to `data/eng-fra.txt` before continuing (for some reason the zipfile is named backwards). The file is a tab separated list of translation pairs:\n",
    "\n",
    "```\n",
    "I am cold.    Je suis froid.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing words\n",
    "\n",
    "We'll need a unique index per word to use as the inputs and targets of the networks later. To keep track of all this we will use a helper class called `Lang` which has word &rarr; index (`word2index`) and index &rarr; word (`index2word`) dictionaries, as well as a count of each word (`word2count`). This class includes a function `trim(min_count)` to remove rare words once they are all counted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and decoding files\n",
    "\n",
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalize_string(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1 \", s)\n",
    "    s = re.sub(r\"[^a-zA-Z,.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English &rarr; Other Language, so if we want to translate from Other Language &rarr; English I added the `reverse` flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "#     filename = '../data/%s-%s.txt' % (lang1, lang2)\n",
    "    filename = '../%s-%s.txt' % (lang1, lang2)\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MIN_LENGTH = 3\n",
    "MAX_LENGTH = 25\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    filtered_pairs = []\n",
    "    for pair in pairs:\n",
    "        if len(pair[0]) >= MIN_LENGTH and len(pair[0]) <= MAX_LENGTH \\\n",
    "            and len(pair[1]) >= MIN_LENGTH and len(pair[1]) <= MAX_LENGTH:\n",
    "                filtered_pairs.append(pair)\n",
    "    return filtered_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "* Read text file and split into lines\n",
    "* Split lines into pairs and normalize\n",
    "* Filter to pairs of a certain length\n",
    "* Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 142224 sentence pairs\n",
      "Filtered to 26705 pairs\n",
      "Indexing words...\n",
      "Indexed 7145 words in input language, 4426 words in output\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %d sentence pairs\" % len(pairs))\n",
    "    \n",
    "    pairs = filter_pairs(pairs)\n",
    "    print(\"Filtered to %d pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Indexing words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "    \n",
    "    print('Indexed %d words in input language, %d words in output' % (input_lang.n_words, output_lang.n_words))\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepare_data('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering vocabularies\n",
    "\n",
    "To get something that trains in under an hour, we'll trim the data set a bit. First we will use the `trim` function on each language (defined above) to only include words that are repeated a certain amount of times through the dataset (this softens the difficulty of learning a correct translation for words that don't appear often)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 1768 / 7142 = 0.2475\n",
      "keep_words 1568 / 4423 = 0.3545\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT = 5\n",
    "\n",
    "input_lang.trim(MIN_COUNT)\n",
    "output_lang.trim(MIN_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering pairs\n",
    "\n",
    "Now we will go back to the set of all sentence pairs and remove those with unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed from 26705 pairs to 16707, 0.6256 of total\n"
     ]
    }
   ],
   "source": [
    "keep_pairs = []\n",
    "\n",
    "for pair in pairs:\n",
    "    input_sentence = pair[0]\n",
    "    output_sentence = pair[1]\n",
    "    keep_input = True\n",
    "    keep_output = True\n",
    "    \n",
    "    for word in input_sentence.split(' '):\n",
    "        if word not in input_lang.word2index:\n",
    "            keep_input = False\n",
    "            break\n",
    "\n",
    "    for word in output_sentence.split(' '):\n",
    "        if word not in output_lang.word2index:\n",
    "            keep_output = False\n",
    "            break\n",
    "\n",
    "    # Remove if pair doesn't match input and output conditions\n",
    "    if keep_input and keep_output:\n",
    "        keep_pairs.append(pair)\n",
    "\n",
    "print(\"Trimmed from %d pairs to %d, %.4f of total\" % (len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "pairs = keep_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning training data into Tensors\n",
    "\n",
    "To train we need to turn the sentences into something the neural network can understand, which of course means numbers. Each sentence will be split into words and turned into a `LongTensor` which represents the index (from the Lang indexes made earlier) of each word. While creating these tensors we will also append the EOS token to signal that the sentence is over.\n",
    "\n",
    "![](https://i.imgur.com/LzocpGH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence, plus EOS\n",
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make better use of the GPU by training on batches of many sequences at once, but doing so brings up the question of how to deal with sequences of varying lengths. The simple solution is to \"pad\" the shorter sentences with some padding symbol (in this case `0`), and ignore these padded spots when calculating the loss.\n",
    "\n",
    "![](https://i.imgur.com/gGlkEEF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad a with the PAD symbol\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [PAD_token for i in range(max_length - len(seq))]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Variable for a full batch of inputs (and targets) we get a random sample of sequences and pad them all to the length of the longest sequence. We'll keep track of the lengths of each batch in order to un-pad later.\n",
    "\n",
    "Initializing a `LongTensor` with an array (batches) of arrays (sequences) gives us a `(batch_size x max_len)` tensor - selecting the first dimension gives you a single batch, which is a full sequence. When training the model we'll want a single time step at once, so we'll transpose to `(max_len x batch_size)`. Now selecting along the first dimension returns a single time step across batches.\n",
    "\n",
    "![](https://i.imgur.com/nBxTG3v.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(batch_size):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "\n",
    "    # Choose random pairs\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "        input_seqs.append(indexes_from_sentence(input_lang, pair[0]))\n",
    "        target_seqs.append(indexes_from_sentence(output_lang, pair[1]))\n",
    "\n",
    "    # Zip into pairs, sort by length (descending), unzip\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs = zip(*seq_pairs)\n",
    "    \n",
    "    # For input and target sequences, get array of lengths and pad with 0s to max length\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    # Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_var = input_var.cuda()\n",
    "        target_var = target_var.cuda()\n",
    "        \n",
    "    return input_var, input_lengths, target_var, target_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this to see that it will return a `(max_len x batch_size)` tensor for input and target sentences, along with a corresponding list of batch lenghts for each (which we will use for masking later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "   928  1329\n",
       "   643  1538\n",
       "  1607  1281\n",
       "  1604   843\n",
       "   503   178\n",
       "   178     2\n",
       "     2     0\n",
       " [torch.LongTensor of size 7x2], [7, 6], Variable containing:\n",
       "    16  1261\n",
       "   534   822\n",
       "   810  1209\n",
       "   875  1435\n",
       "   566   285\n",
       "   285     2\n",
       "     2     0\n",
       " [torch.LongTensor of size 7x2], [7, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Encoder\n",
    "\n",
    "<img src=\"images/encoder-network.png\" style=\"float: right\" />\n",
    "\n",
    "The encoder will take a batch of word sequences, a `LongTensor` of size `(max_len x batch_size)`, and output an encoding for each word, a `FloatTensor` of size `(max_len x batch_size x hidden_size)`.\n",
    "\n",
    "The word inputs are fed through an [embedding layer `nn.Embedding`](http://pytorch.org/docs/nn.html#embedding) to create an embedding for each word, with size `seq_len x hidden_size` (as if it was a batch of words). This is resized to `seq_len x 1 x hidden_size` to fit the expected input of the [GRU layer `nn.GRU`](http://pytorch.org/docs/nn.html#gru). The GRU will return both an output sequence of size `seq_len x hidden_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Bahdanau et al. model\n",
    "\n",
    "[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) (Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio) introduced the idea of using attention for seq2seq translation.\n",
    "\n",
    "Each decoder output is conditioned on the previous outputs and some $\\mathbf x$, where $\\mathbf x$ consists of the current hidden state (which takes into account previous outputs) and the attention \"context\", which is calculated below. The function $g$ is a fully-connected layer with a nonlinear activation, which takes as input the values $y_{i-1}$, $s_i$, and $c_i$ concatenated.\n",
    "\n",
    "$$\n",
    "p(y_i \\mid \\{y_1,...,y_{i-1}\\},\\mathbf{x}) = g(y_{i-1}, s_i, c_i)\n",
    "$$\n",
    "\n",
    "The current hidden state $s_i$ is calculated by an RNN $f$ with the last hidden state $s_{i-1}$, last decoder output value $y_{i-1}$, and context vector $c_i$.\n",
    "\n",
    "In the code, the RNN will be a `nn.GRU` layer, the hidden state $s_i$ will be called `hidden`, the output $y_i$ called `output`, and context $c_i$ called `context`.\n",
    "\n",
    "$$\n",
    "s_i = f(s_{i-1}, y_{i-1}, c_i)\n",
    "$$\n",
    "\n",
    "The context vector $c_i$ is a weighted sum of all encoder outputs, where each weight $a_{ij}$ is the amount of \"attention\" paid to the corresponding encoder output $h_j$.\n",
    "\n",
    "$$\n",
    "c_i = \\sum_{j=1}^{T_x} a_{ij} h_j\n",
    "$$\n",
    "\n",
    "... where each weight $a_{ij}$ is a normalized (over all steps) attention \"energy\" $e_{ij}$ ...\n",
    "\n",
    "$$\n",
    "a_{ij} = \\dfrac{exp(e_{ij})}{\\sum_{k=1}^{T} exp(e_{ik})}\n",
    "$$\n",
    "\n",
    "... where each attention energy is calculated with some function $a$ (such as another linear layer) using the last hidden state $s_{i-1}$ and that particular encoder output $h_j$:\n",
    "\n",
    "$$\n",
    "e_{ij} = a(s_{i-1}, h_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Luong et al. models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025) (Minh-Thang Luong, Hieu Pham, Christopher D. Manning) describe a few more attention models that offer improvements and simplifications. They describe a few \"global attention\" models, the distinction between them being the way the attention scores are calculated.\n",
    "\n",
    "The general form of the attention calculation relies on the target (decoder) side hidden state and corresponding source (encoder) side state, normalized over all states to get values summing to 1:\n",
    "\n",
    "$$\n",
    "a_t(s) = align(h_t, \\bar h_s)  = \\dfrac{exp(score(h_t, \\bar h_s))}{\\sum_{s'} exp(score(h_t, \\bar h_{s'}))}\n",
    "$$\n",
    "\n",
    "The specific \"score\" function that compares two states is either *dot*, a simple dot product between the states; *general*, a a dot product between the decoder hidden state and a linear transform of the encoder state; or *concat*, a dot product between a new parameter $v_a$ and a linear transform of the states concatenated together.\n",
    "\n",
    "$$\n",
    "score(h_t, \\bar h_s) =\n",
    "\\begin{cases}\n",
    "h_t ^\\top \\bar h_s & dot \\\\\n",
    "h_t ^\\top \\textbf{W}_a \\bar h_s & general \\\\\n",
    "v_a ^\\top \\textbf{W}_a [ h_t ; \\bar h_s ] & concat\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The modular definition of these scoring functions gives us an opportunity to build specific attention module that can switch between the different score methods. The input to this module is always the hidden state (of the decoder RNN) and set of encoder outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing an attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = hidden.dot(encoder_output)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = self.v.dot(energy)\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the Bahdanau et al. model\n",
    "\n",
    "In summary our decoder should consist of four main parts - an embedding layer turning an input word into a vector; a layer to calculate the attention energy per encoder output; a RNN layer; and an output layer.\n",
    "\n",
    "The decoder's inputs are the last RNN hidden state $s_{i-1}$, last output $y_{i-1}$, and all encoder outputs $h_*$.\n",
    "\n",
    "* embedding layer with inputs $y_{i-1}$\n",
    "    * `embedded = embedding(last_rnn_output)`\n",
    "* attention layer $a$ with inputs $(s_{i-1}, h_j)$ and outputs $e_{ij}$, normalized to create $a_{ij}$\n",
    "    * `attn_energies[j] = attn_layer(last_hidden, encoder_outputs[j])`\n",
    "    * `attn_weights = normalize(attn_energies)`\n",
    "* context vector $c_i$ as an attention-weighted average of encoder outputs\n",
    "    * `context = sum(attn_weights * encoder_outputs)`\n",
    "* RNN layer(s) $f$ with inputs $(s_{i-1}, y_{i-1}, c_i)$ and internal hidden state, outputting $s_i$\n",
    "    * `rnn_input = concat(embedded, context)`\n",
    "    * `rnn_output, rnn_hidden = rnn(rnn_input, last_hidden)`\n",
    "* an output layer $g$ with inputs $(y_{i-1}, s_i, c_i)$, outputting $y_i$\n",
    "    * `output = out(embedded, rnn_output, context)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        # TODO: FIX BATCHING\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build a decoder that plugs this Attn module in after the RNN to calculate attention weights, and apply those weights to the encoder outputs to get a context vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "        # Get current hidden state from input word and last hidden state\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs;\n",
    "        # apply to encoder outputs to get weighted average\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x S=1 x N\n",
    "\n",
    "        # Attentional vector using the RNN hidden state and context vector\n",
    "        # concatenated together (Luong eq. 5)\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        # Finally predict next token (Luong eq. 6, without softmax)\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models\n",
    "\n",
    "To make sure the encoder and decoder modules are working (and working together) we'll do a full test with a small batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_batches torch.Size([8, 3])\n",
      "target_batches torch.Size([7, 3])\n"
     ]
    }
   ],
   "source": [
    "small_batch_size = 3\n",
    "input_batches, input_lengths, target_batches, target_lengths = random_batch(small_batch_size)\n",
    "\n",
    "print('input_batches', input_batches.size()) # (max_len x batch_size)\n",
    "print('target_batches', target_batches.size()) # (max_len x batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models with a small size (a good idea for eyeball inspection):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_hidden_size = 8\n",
    "small_n_layers = 2\n",
    "\n",
    "encoder_test = EncoderRNN(input_lang.n_words, small_hidden_size, small_n_layers)\n",
    "decoder_test = LuongAttnDecoderRNN('general', small_hidden_size, output_lang.n_words, small_n_layers)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    decoder_test.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the encoder, run the input batch through to get per-batch encoder outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs torch.Size([8, 3, 8])\n",
      "encoder_hidden torch.Size([4, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs, encoder_hidden = encoder_test(input_batches, input_lengths, None)\n",
    "\n",
    "print('encoder_outputs', encoder_outputs.size()) # max_len x batch_size x hidden_size\n",
    "print('encoder_hidden', encoder_hidden.size()) # n_layers * 2 x batch_size x hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then starting with a SOS token, run word tokens through the decoder to get each next word token. Instead of doing this with the whole sequence, it is done one at a time, to support using it's own predictions to make the next prediction. This will be one time step at a time, but batched per time step. In order to get this to work for short padded sequences, the batch size is going to get smaller each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 7.398756980895996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/github/practical-pytorch/seq2seq-translation/masked_cross_entropy.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    }
   ],
   "source": [
    "max_target_length = max(target_lengths)\n",
    "\n",
    "# Prepare decoder input and outputs\n",
    "decoder_input = Variable(torch.LongTensor([SOS_token] * small_batch_size))\n",
    "decoder_hidden = encoder_hidden[:decoder_test.n_layers] # Use last (forward) hidden state from encoder\n",
    "all_decoder_outputs = Variable(torch.zeros(max_target_length, small_batch_size, decoder_test.output_size))\n",
    "\n",
    "if USE_CUDA:\n",
    "    all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "    decoder_input = decoder_input.cuda()\n",
    "\n",
    "# Run through decoder one time step at a time\n",
    "for t in range(max_target_length):\n",
    "    decoder_output, decoder_hidden, decoder_attn = decoder_test(\n",
    "        decoder_input, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    all_decoder_outputs[t] = decoder_output # Store this step's outputs\n",
    "    decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "# Test masked cross entropy loss\n",
    "loss = masked_cross_entropy(\n",
    "    all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "    target_batches.transpose(0, 1).contiguous(),\n",
    "    target_lengths\n",
    ")\n",
    "print('loss', loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Defining a training iteration\n",
    "\n",
    "To train we first run the input sentence through the encoder word by word, and keep track of every output and the latest hidden state. Next the decoder is given the last hidden state of the decoder as its first hidden state, and the `<SOS>` token as its first input. From there we iterate to predict a next token from the decoder.\n",
    "\n",
    "### Teacher Forcing vs. Scheduled Sampling\n",
    "\n",
    "\"Teacher Forcing\", or maximum likelihood sampling, means using the real target outputs as each next input when training. The alternative is using the decoder's own guess as the next input. Using teacher forcing may cause the network to converge faster, but [when the trained network is exploited, it may exhibit instability](http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf).\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - you could think of it as having learned how to listen to the teacher's instructions, without learning how to venture out on its own.\n",
    "\n",
    "The solution to the teacher-forcing \"problem\" is known as [Scheduled Sampling](https://arxiv.org/abs/1506.03099), which simply alternates between using the target values and predicted values when training. We will randomly choose to use teacher forcing with an if statement while training - sometimes we'll feed use real target as the input (ignoring the decoder's output), sometimes we'll use the decoder's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    # Move new Variables to CUDA\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "    \n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        print('teacher forcing')\n",
    "        # Run through decoder one time step at a time\n",
    "        for t in range(max_target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "\n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            decoder_input = target_batches[t] # Next input is current target\n",
    "\n",
    "    else:\n",
    "        print('live')\n",
    "        # create indicator tensor for end of sentence\n",
    "        end_of_sentence = torch.zeros(target_batches.size()[1])\n",
    "        # mask for prediction\n",
    "        mask = end_of_sentence.ge(1)\n",
    "        # create placeholder for output predictions\n",
    "        output_placeholder = torch.zeros(target_batches.size())\n",
    "        if USE_CUDA:\n",
    "            end_of_sentence = end_of_sentence.cuda()\n",
    "            mask = mask.cuda()\n",
    "            output_placeholder = output_placeholder.cuda()\n",
    "        \n",
    "        # Run through decoder one time step at a time\n",
    "        for t in range(max_target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "\n",
    "            all_decoder_outputs[t] = decoder_output\n",
    "            # make next input current prediction\n",
    "            _, ni = decoder_output.data.topk(1)\n",
    "            output_placeholder[t] = ni\n",
    "            output_placeholder[t] = output_placeholder[t].masked_fill_(\n",
    "                mask, PAD_token)\n",
    "            # update maske\n",
    "            end_of_sentence.add_(ni.eq(EOS_token).float())\n",
    "            mask = end_of_sentence.ge(1)\n",
    "            \n",
    "            decoder_input = Variable(ni)\n",
    "            \n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "            \n",
    "    # Loss calculation and backpropagation\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_batches.transpose(0, 1).contiguous(), # -> batch x seq\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip gradient norms\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    # Update parameters with optimizers\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0], ec, dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running training\n",
    "\n",
    "With everything in place we can actually initialize a network and start training.\n",
    "\n",
    "To start, we initialize models, optimizers, a loss function (criterion), and set up variables for plotting and tracking progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting job 59541067f8e1c2083c2419e9 at 2017-06-28 16:24:07\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 50\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 50000\n",
    "epoch = 0\n",
    "plot_every = 20\n",
    "print_every = 100\n",
    "evaluate_every = 1000\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "import sconce\n",
    "job = sconce.Job('seq2seq-translate', {\n",
    "    'attn_model': attn_model,\n",
    "    'n_layers': n_layers,\n",
    "    'dropout': dropout,\n",
    "    'hidden_size': hidden_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'clip': clip,\n",
    "    'teacher_forcing_ratio': teacher_forcing_ratio,\n",
    "    'decoder_learning_ratio': decoder_learning_ratio,\n",
    "})\n",
    "job.plot_every = plot_every\n",
    "job.log_every = print_every\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus helper functions to print time elapsed and estimated time remaining, given the current time and progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the network\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself. Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(input_seq, max_length=MAX_LENGTH):\n",
    "    input_lengths = [len(input_seq)]\n",
    "    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "        \n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    [input_sentence, target_sentence] = random.choice(pairs)\n",
    "    evaluate_and_show_attention(input_sentence, target_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing attention\n",
    "\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.\n",
    "\n",
    "You could simply run `plt.matshow(attentions)` to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import visdom\n",
    "vis = visdom.Visdom()\n",
    "\n",
    "def show_plot_visdom():\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf)\n",
    "    buf.seek(0)\n",
    "    attn_win = 'attention (%s)' % hostname\n",
    "    vis.image(torchvision.transforms.ToTensor()(Image.open(buf)), win=attn_win, opts={'title': attn_win})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better viewing experience we will do the extra work of adding axes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    show_plot_visdom()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_and_show_attention(input_sentence, target_sentence=None):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('>', input_sentence)\n",
    "    if target_sentence is not None:\n",
    "        print('=', target_sentence)\n",
    "    print('<', output_sentence)\n",
    "    \n",
    "    show_attention(input_sentence, output_words, attentions)\n",
    "    \n",
    "    # Show input, target, output text in visdom\n",
    "    win = 'evaluted (%s)' % hostname\n",
    "    text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n",
    "    vis.text(text, win=win, opts={'title': win})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "**TODO** Run `train_epochs` for `n_epochs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually train, we call the train function many times, printing a summary as we go.\n",
    "\n",
    "*Note:* If you're running this notebook you can **train, interrupt, evaluate, and come back to continue training**. Simply run the notebook starting from the following cell (running from the previous cell will reset the models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher forcing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrick/github/practical-pytorch/seq2seq-translation/masked_cross_entropy.py:9: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.3. Note that arange generates values in [start; end), not [start; end].\n",
      "  seq_range = torch.range(0, max_len - 1).long()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 0s (- 27m 3s) (18 3%) 4.3967\n",
      "live\n",
      "1m 1s (- 25m 47s) (19 3%) 4.9595\n",
      "teacher forcing\n",
      "1m 1s (- 24m 38s) (20 4%) 4.5774\n",
      "teacher forcing\n",
      "1m 2s (- 23m 35s) (21 4%) 4.5254\n",
      "teacher forcing\n",
      "1m 2s (- 22m 38s) (22 4%) 4.8522\n",
      "live\n",
      "1m 2s (- 21m 45s) (23 4%) 4.7207\n",
      "live\n",
      "1m 3s (- 20m 59s) (24 4%) 4.4059\n",
      "teacher forcing\n",
      "1m 3s (- 20m 15s) (25 5%) 4.9462\n",
      "live\n",
      "1m 4s (- 19m 34s) (26 5%) 4.1879\n",
      "teacher forcing\n",
      "1m 4s (- 18m 56s) (27 5%) 4.9808\n",
      "teacher forcing\n",
      "1m 5s (- 18m 21s) (28 5%) 4.8732\n",
      "live\n",
      "1m 5s (- 17m 48s) (29 5%) 4.1055\n",
      "teacher forcing\n",
      "1m 6s (- 17m 18s) (30 6%) 4.7282\n",
      "teacher forcing\n",
      "1m 6s (- 16m 49s) (31 6%) 4.3436\n",
      "teacher forcing\n",
      "1m 7s (- 16m 22s) (32 6%) 3.5684\n",
      "teacher forcing\n",
      "1m 7s (- 15m 57s) (33 6%) 4.1545\n",
      "live\n",
      "1m 8s (- 15m 35s) (34 6%) 4.4927\n",
      "live\n",
      "1m 8s (- 15m 15s) (35 7%) 4.6048\n",
      "live\n",
      "1m 9s (- 14m 55s) (36 7%) 4.5162\n",
      "teacher forcing\n",
      "1m 9s (- 14m 35s) (37 7%) 3.8663\n",
      "live\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-323b63aabcda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minput_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-93f1a236f65e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_target_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             decoder_output, decoder_hidden, decoder_attn = decoder(\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             )\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-5aa7759843b6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Get current hidden state from input word and last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Calculate attention from current RNN state and all encoder outputs;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mdropout_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutogradRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# cuBLAS doesn't support 0 strides in sger, so we can't use expand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "\n",
    "while epoch < n_epochs:\n",
    "    epoch += 1\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "\n",
    "    # Run the train function\n",
    "    loss, ec, dc = train(\n",
    "        input_batches, input_lengths, target_batches, target_lengths,\n",
    "        encoder, decoder,\n",
    "        encoder_optimizer, decoder_optimizer, criterion\n",
    "    )\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "    eca += ec\n",
    "    dca += dc\n",
    "    \n",
    "    job.record(epoch, loss)\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "        \n",
    "    if epoch % evaluate_every == 0:\n",
    "        evaluate_randomly()\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0\n",
    "        \n",
    "        # TODO: Running average helper\n",
    "        ecs.append(eca / plot_every)\n",
    "        dcs.append(dca / plot_every)\n",
    "        ecs_win = 'encoder grad (%s)' % hostname\n",
    "        dcs_win = 'decoder grad (%s)' % hostname\n",
    "        vis.line(np.array(ecs), win=ecs_win, opts={'title': ecs_win})\n",
    "        vis.line(np.array(dcs), win=dcs_win, opts={'title': dcs_win})\n",
    "        eca = 0\n",
    "        dca = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training loss\n",
    "\n",
    "Plotting is done with matplotlib, using the array `plot_losses` that was created while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d5d978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhAAAAFkCAYAAABxWwLDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d5de80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAFdCAYAAAAXGYTVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWj1JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112443c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\"je suis trop froid .\")\n",
    "plt.matshow(attentions.numpy())\n",
    "show_plot_visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> elle a cinq ans de moins que moi .\n",
      "< i i . <EOS>\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFRCAYAAADpda42AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbx+cDrXSoE8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11884b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"elle a cinq ans de moins que moi .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> elle est trop petit .\n",
      "< i is . <EOS>\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFrCAYAAABMlIr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf2lifEp5skYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11893a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"elle est trop petit .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je ne crains pas de mourir .\n",
      "< i i . <EOS>\n",
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFRCAYAAADpda42AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nil7O2y/NAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d62ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 370, in send\n",
      "    timeout=timeout\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 597, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/retry.py\", line 245, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/packages/six.py\", line 309, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 544, in urlopen\n",
      "    body=body, headers=headers)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connectionpool.py\", line 349, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1106, in request\n",
      "    self._send_request(method, url, body, headers)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1151, in _send_request\n",
      "    self.endheaders(body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 1102, in endheaders\n",
      "    self._send_output(message_body)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 934, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/http/client.py\", line 877, in send\n",
      "    self.connect()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 155, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/connection.py\", line 134, in _new_conn\n",
      "    (self.host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 88, in create_connection\n",
      "    raise err\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/packages/urllib3/util/connection.py\", line 78, in create_connection\n",
      "    sock.connect(sa)\n",
      "requests.packages.urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/visdom/__init__.py\", line 228, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 109, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/api.py\", line 50, in request\n",
      "    response = session.request(method=method, url=url, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 465, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/sessions.py\", line 573, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/Users/patrick/.virtualenvs/ziebell/lib/python3.5/site-packages/requests/adapters.py\", line 415, in send\n",
      "    raise ConnectionError(err, request=request)\n",
      "requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"je ne crains pas de mourir .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'directeur'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-dbefade784e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"c est un jeune directeur plein de talent .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-2d180e375790>\u001b[0m in \u001b[0;36mevaluate_and_show_attention\u001b[0;34m(input_sentence, target_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_sentence\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-7c7ad46324f6>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(input_seq, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-23cfd0d0da92>\u001b[0m in \u001b[0;36mindexes_from_sentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Return a list of indexes, one for each word in the sentence, plus EOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-23cfd0d0da92>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Return a list of indexes, one for each word in the sentence, plus EOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'directeur'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"est le chien vert aujourd hui ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"le chat me parle .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"des centaines de personnes furent arretees ici .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evaluate_and_show_attention(\"des centaines de chiens furent arretees ici .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fromage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-2d53b90ad835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ce fromage est prepare a partir de lait de chevre .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-2d180e375790>\u001b[0m in \u001b[0;36mevaluate_and_show_attention\u001b[0;34m(input_sentence, target_sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_and_show_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_sentence\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-7c7ad46324f6>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(input_seq, max_length)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minput_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0minput_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolatile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-23cfd0d0da92>\u001b[0m in \u001b[0;36mindexes_from_sentence\u001b[0;34m(lang, sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Return a list of indexes, one for each word in the sentence, plus EOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-23cfd0d0da92>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Return a list of indexes, one for each word in the sentence, plus EOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mindexes_from_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'fromage'"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_attention(\"ce fromage est prepare a partir de lait de chevre .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises\n",
    "\n",
    "* Try with a different dataset\n",
    "    * Another language pair\n",
    "    * Human &rarr; Machine (e.g. IOT commands)\n",
    "    * Chat &rarr; Response\n",
    "    * Question &rarr; Answer\n",
    "* Replace the embedding pre-trained word embeddings such as word2vec or GloVe\n",
    "* Try with more layers, more hidden units, and more sentences. Compare the training time and results.\n",
    "* If you use a translation file where pairs have two of the same phrase (`I am test \\t I am test`), you can use this as an autoencoder. Try this:\n",
    "    * Train as an autoencoder\n",
    "    * Save only the Encoder network\n",
    "    * Train a new Decoder for translation from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
